{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [0, 2, 0, 3],\n",
    "    [0, 1, 4, 3],\n",
    "    [0.1, 1, 1, 3]], \n",
    "    dtype=np.float32)\n",
    "Y = np.array([1, 2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VarianceThreshold(threshold=0.1)\n",
      "-----------------\n",
      "[[2. 0.]\n",
      " [1. 4.]\n",
      " [1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# 方差选择法\n",
    "variance = VarianceThreshold(threshold=0.1)\n",
    "print(variance)\n",
    "print('-----------------')\n",
    "variance.fit(X)\n",
    "print(variance.transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelectKBest(k=2, score_func=<function f_regression at 0x0000025012893488>)\n",
      "------------\n",
      "[ 0.33333333  0.33333333 16.33333333         nan]\n",
      "------------\n",
      "[[0.  0. ]\n",
      " [0.  4. ]\n",
      " [0.1 1. ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Software\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:298: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  corr /= X_norms\n",
      "C:\\Software\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:303: RuntimeWarning: invalid value encountered in true_divide\n",
      "  F = corr ** 2 / (1 - corr ** 2) * degrees_of_freedom\n",
      "C:\\Software\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "C:\\Software\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "C:\\Software\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    }
   ],
   "source": [
    "# 相关系数法\n",
    "sk1 = SelectKBest(f_regression, k=2)\n",
    "sk1.fit(X, Y)\n",
    "print(sk1)\n",
    "print('------------')\n",
    "print(sk1.scores_)\n",
    "print('------------')\n",
    "print(sk1.transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelectKBest(k=2, score_func=<function chi2 at 0x0000025012893400>)\n",
      "[0.05  0.125 4.9   0.   ]\n",
      "[[2. 0.]\n",
      " [1. 4.]\n",
      " [1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# 卡方检验\n",
    "# 使用chi2的时候要求特征属性为非负数\n",
    "sk2 = SelectKBest(chi2, k=2)\n",
    "sk2.fit(X, Y)\n",
    "print(sk2)\n",
    "print(sk2.scores_)\n",
    "print(sk2.transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFE(estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "  kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n",
      "  n_features_to_select=2, step=1, verbose=0)\n",
      "[False  True  True False]\n",
      "2\n",
      "[2 1 1 3]\n",
      "[[2. 0.]\n",
      " [1. 4.]\n",
      " [1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# 包装法Wrapper：特征递归特征消除法\n",
    "estimator = SVR(kernel='linear')\n",
    "selector = RFE(estimator, 2, step=1)\n",
    "selector = selector.fit(X, Y)\n",
    "print(selector)\n",
    "print(selector.support_)\n",
    "print(selector.n_features_)\n",
    "print(selector.ranking_)\n",
    "print(selector.transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelectFromModel(estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "        norm_order=1, prefit=False, threshold=None)\n",
      "[[ 5.1]\n",
      " [ 4.9]\n",
      " [-6.2]\n",
      " [-5.9]]\n"
     ]
    }
   ],
   "source": [
    "# 基于惩罚项的特征选择法\n",
    "X2 = np.array([\n",
    "    [5.1, 3.5, 1.4, 0.2],\n",
    "    [4.9, 3. , 1.4, 0.2],\n",
    "    [-6.2, 0.4, 5.4, 2.3],\n",
    "    [-5.9, 0. , 5.1, 1.8]], \n",
    "    dtype=np.float64)\n",
    "Y2 = np.array([0, 0, 2, 2])\n",
    "estimator = LogisticRegression(penalty='l1', C=0.1)\n",
    "sfm = SelectFromModel(estimator)\n",
    "sfm.fit(X2, Y2)\n",
    "print(sfm)\n",
    "print(sfm.transform(X2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelectFromModel(estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False),\n",
      "        norm_order=1, prefit=False, threshold=None)\n",
      "[[ 5.1  1.4]\n",
      " [ 4.9  1.4]\n",
      " [-6.2  5.4]\n",
      " [-5.9  5.1]]\n"
     ]
    }
   ],
   "source": [
    "# 基于树模型的特征选择法\n",
    "estimator = GradientBoostingClassifier()\n",
    "sfm = SelectFromModel(estimator)\n",
    "sfm.fit(X2, Y2)\n",
    "print(sfm)\n",
    "print(sfm.transform(X2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.525  1.725  3.325  1.125  1.825 12.775]\n",
      "[[ 0.02038178 -0.01698103 -0.01350052 -0.0149724   0.03184796 -0.99893718]\n",
      " [ 0.9024592   0.25030511 -0.31422084 -0.15092666 -0.03185873  0.01965141]\n",
      " [-0.08872116 -0.06952185 -0.06858116 -0.3074396  -0.94204108 -0.02512755]\n",
      " [ 0.08903791  0.59899454  0.78582815 -0.09643168 -0.07779466 -0.02002095]]\n",
      "[[-1.01160631e+01  6.49232600e+00  3.14197238e-01  2.22044605e-16]\n",
      " [ 1.08075405e+01  5.73455069e+00 -3.32785235e-01  2.22044605e-16]\n",
      " [-1.03473322e+01 -6.08709685e+00 -3.29724759e-01  4.44089210e-16]\n",
      " [ 9.65585479e+00 -6.13977984e+00  3.48312756e-01 -1.11022302e-16]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X2 = np.array([\n",
    "    [ 5.1,  3.5,  1.4,  0.2, 1, 23],\n",
    "    [ 4.9,  3. ,  1.4,  0.2, 2.3, 2.1],\n",
    "    [ -6.2,  0.4,  5.4,  2.3, 2, 23],\n",
    "    [ -5.9,  0. ,  5.1,  1.8, 2, 3]], \n",
    "    dtype=np.float64)\n",
    "# n_components: 给定降低到多少维度，但是要求该值必须小于等于样本数目/特征数目，\n",
    "# 如果给定的值大于，那么会选择样本数目/特征数目中最小的那个作为最终的特征数目\n",
    "pca = PCA(n_components=6)\n",
    "pca.fit(X2)\n",
    "print(pca.mean_)\n",
    "print(pca.components_)\n",
    "print(pca.transform(X2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.2688434  -0.38911349]\n",
      " [-1.25507558 -1.78088569]\n",
      " [ 5.26064254 -0.49688862]\n",
      " [ 6.34385833  1.16134391]\n",
      " [-4.05800618  3.58297801]\n",
      " [-3.02257571 -2.07743411]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Software\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "X = np.array([\n",
    "    [-1, -1, 3, 1], \n",
    "    [-2, -1, 2, 4], \n",
    "    [-3, -2, 4, 5], \n",
    "    [1, 1, 5, 4], \n",
    "    [2, 1, 6, -5], \n",
    "    [3, 2, 1, 5]\n",
    "    ])\n",
    "y = np.array([1, 1, 2, 2, 0, 1])\n",
    "# n_components：给定降低到多少维度，要求给定的这个值和y的取值数量有关，不能超过n_class-1\n",
    "clf = LinearDiscriminantAnalysis(n_components=2)\n",
    "clf.fit(X, y)\n",
    "print(clf.transform(X))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
